# LLM Multiple-Choice Exam Tester

A streamlined testing framework for evaluating Local LLMs on multiple-choice exam questions using Ollama.

![Python Version](https://img.shields.io/badge/python-3.8%2B-blue)
![Streamlit](https://img.shields.io/badge/streamlit-1.32%2B-red)
![License](https://img.shields.io/badge/license-MIT-green)

## Features

- 📁 **Easy Data Upload**: Load questions and answers from CSV files
- 🤖 **Local LLM Testing**: Test any Ollama-supported model
- 📊 **Real-time Results**: View scores and detailed results immediately
- 📈 **Performance Tracking**: Compare results across different models and tests
- 💾 **Data Persistence**: All results saved for future analysis
- 🎨 **Interactive UI**: Clean Streamlit interface with progress tracking

## Quick Start

### Prerequisites

1. **Python 3.8+** installed
2. **Ollama** installed and running
3. At least one LLM model downloaded via Ollama

### Installation

1. Clone the repository:
```bash
git clone https://github.com/Borisvdk/ModelTesting.git
cd llm-exam-tester
```

2. Create a virtual environment: