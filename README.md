# LLM Multiple-Choice Exam Tester

A streamlined testing framework for evaluating Local LLMs on multiple-choice exam questions using Ollama.

![Python Version](https://img.shields.io/badge/python-3.8%2B-blue)
![Streamlit](https://img.shields.io/badge/streamlit-1.32%2B-red)
![License](https://img.shields.io/badge/license-MIT-green)

## Features

- ğŸ“ **Easy Data Upload**: Load questions and answers from CSV files
- ğŸ¤– **Local LLM Testing**: Test any Ollama-supported model
- ğŸ“Š **Real-time Results**: View scores and detailed results immediately
- ğŸ“ˆ **Performance Tracking**: Compare results across different models and tests
- ğŸ’¾ **Data Persistence**: All results saved for future analysis
- ğŸ¨ **Interactive UI**: Clean Streamlit interface with progress tracking

## Quick Start

### Prerequisites

1. **Python 3.8+** installed
2. **Ollama** installed and running
3. At least one LLM model downloaded via Ollama

### Installation

1. Clone the repository:
```bash
git clone https://github.com/Borisvdk/ModelTesting.git
cd llm-exam-tester
```

2. Create a virtual environment: